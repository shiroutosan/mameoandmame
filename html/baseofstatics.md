# 統計学入門（東大出版会）
## 2.1度数分布の区分数の決め方
標本数が$n$のとき、適切な区分数$k$は、スタージェスの公式を用いて

$k≒1+log_2n$

## 3.3 相関係数
### 相関係数の定義
データが$x_i$と$y_i$の組み合わせで与えられているとき、相関係数$r_{xy}$は

$$
r_{xy}=\frac{Cov(x,y)}{V(x)V(y)} \\
=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})/n}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2/n}\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2/n}}
$$

$x_i,y_i$を標準化得点$z_i,w_i$に置き換えると、

標準化得点の平均=0・分散=1なので、
相関係数は

$\frac{1}{n}\sum{z_iw_i}$

となる。

### 偏相関係数
要素1・要素2・要素3があり、互いにある程度の相関があるとする。

要素1と要素3、要素2と要素3に相関があることが原因で、要素1と要素2の相関係数が過剰に計算されている疑いがあるときは、偏相関係数を用いる。

要素3の影響を排除した後の要素1と要素2の偏相関係数$r_{12・3}$は、

$$
r_{12・3}=\frac{r_{12}-r_{13}r_{23}}{\sqrt{1-{r_{13}}^2}\sqrt{1-{r_{23}}^2}}
$$

### 順位相関係数
２つの要素（例：身長・体重）を持つ標本があるとき、
<br>各要素の順位を使用した相関係数を順位相関係数という。

なお、どちらの順位相関係数とも、同率順位は扱えないので、
何らかの方法で順位付けをする。
#### スピアマンの順位相関係数
$n$人のクラスにおける、$i$さんの身長・体重の順位を$R_i^1$、$R_i^2$とすると、
スピアマンの順位相関係数$r_sは、
$$
r_s=1-\frac{6}{(n^3-n)}\sum_{i=1}^n{(R_i^1-R_i^2)^2}
$$


#### ケンドールの順位相関係数
$n$人のクラスにおける、$i$さんの身長・体重の順位を$R_i^1$、$R_i^2$

$j$さんの身長・体重の順位を$R_j^1$、$R_j^2$とする。
$R_i^1$と$R_j^1$、$R_i^2$と$R_j^2$が同じ、つまり

$G$：身長が大きい方が体重も大きい、という関係があるiさんとjさんのペア数

$H$：身長が大きい方が体重は小さい、という関係があるiさんとjさんのペア数
とする。
ペア数は$n(n+1)/2$なので、ケンドールの順位相関係数$r_k$は、

$r_k=\frac{G-H}{n(n+1)/2}$

#### 自己相関係数
時系列データに対して、異時点間の相関関係を表す係数

時点$i$が期間$n$だけあるとする。（例：1か月ごとの平均気温が12ヵ月分）

$\bar{x}=(x_1+x_2+・・・+x_n)/n$（例：年平均気温）

自己相関係数は、

$\displaystyle r_1=\frac{\sum_{i=1}^{n-1}{(x_i-\bar{x})(x_{i+h}-\bar{x})/(n-h)}}{\sum{(x_i-\bar{x})^2}/n}$

で定義される。

自己相関係数の見方：

- 連続性の尺度として
  - 「自己単相関が高くなるのは、$x_n$と$x_{n+1}$の値が近い」、という事は、<br>「自己単相関が高い　＝　値がほぼ連続的につながっている」
という意味にもなる。 

- 周期性の尺度として
  - データに周期性があると、1ステップ前後以外の値との自己相関も高いことがある。<br>2018年1月と2019年1月、2018年5月と2018年5月・・・で値にあまり差がない場合、式より自己相関係数は1に近づく。<br>全体としては$x_i$が連続しているにも関わらず、間隔の同じ異時点間ペアで値があまり変わらないということは、時系列データ$x$に周期性があると判断する。

## 3.4　直線および平面のあてはめ

説明変数を$x_i$、目的変数を$y_i$とする。

### 回帰係数

単回帰$y_i=a+bx_i$における、直線の傾きbは

$$b=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}
$$

相関係数$r$は
$$
r=\frac{\sum{(x_i-\bar{x})(y_i-\bar{y})/n}}{\sqrt{\sum{(x_i-\bar{x})^2/n}}\sqrt{\sum{(y_i-\bar{y})^2/n}}}
$$

なので、

$$
b=\frac{\sum{(x_i-\bar{x})(y_i-\bar{y})/n}}{\sqrt{\sum{(x_i-\bar{x})^2/n}}\sqrt{\sum{(y_i-\bar{y})^2/n}}}・\frac{\sqrt{\sum{(y_i-\bar{y})^2/n}}}{\sqrt{\sum{(x_i-\bar{x})^2/n}}}\\
=r・\frac{S_y}{S_x}
$$

相関係数が高い（絶対値が大きい）ほど、実際の値$y_i$と、回帰式による予測値$\hat{y}の残差平方和は0に近づく。$x$が$y$を決定する強弱の度合を表すので、符号の影響を排除した$r^2$を決定係数とよぶ。

## 4.2標本空間と事象
$n!$はnが大きくなると計算が大変。

スターリングの公式から$log_en!$の近似値を求められる。


## 5.2確率変数の期待値と分散

$X$という名前の確率変数が取りうる値$x$が、それぞれどれぐらいの確率で出現する（事象として確認される）のかを表す確率密度関数を$f(x)$とすると、

確率変数$X$の期待値$E(X)$・分散$V(X)$は、

期待値：

$\displaystyle E(x)=\sum_{i=1}^nx_if(x)$　　 (離散型)

$\displaystyle E(x)=\int_{-\infty}^{\infty}xf(x)dx$　　（連続型）

例：指数分布の場合

$$\displaystyle E(x)=\int_{-\infty}^{\infty}x(\lambda e^{-\lambda x})dx \\
=1/\lambda
$$

期待値に関する演算則
$$
\displaystyle 
E(c)=c\\
E(X+c)=E(X)+c\\
E(cX)=cE(X)\\
E(X+Y)=E(X)+E(Y)\\
※cは定数

E(XY)=E(X)E(Y)※XとYが独立のときのみ\\
$$

分散：

期待値を$\mu$とする。

$\displaystyle V(x)=\sum_{i=1}^n(x_i-\mu)^2f(x)$　　 (離散型)

$\displaystyle E(x)=\int_{-\infty}^{\infty}(x-\mu)^2f(x)dx$　　（連続型）

また、

$(x-\mu)^2f(x)=x^2f(x)-2\mu xf(x)+\mu^2f(x)$なので、

$$V(X)=E(X^2)-2E(X)^2+E(X)^2\\
=E(X^2)-E(X)^2
$$

分散に関する演算則
$$
\displaystyle 
V(c)=0\\
V(X+c)=V(X)\\
V(cX)=c^2V(X)\\
V(X+Y)=V(X)+V(Y)+2Cov(X,Y)\\
※cは定数
$$

## 5.3モーメント母関数

### 歪度

$\alpha_3=E(x-\mu)^3/\sigma^3$

$\alpha_3>0$のとき、**右に裾が長い**

### 尖度

$\alpha_4=E(x-\mu)^3/\sigma^4$

※$\sigma$は標準偏差

正規分布の尖度は3なので、それとの比較$\alpha_3-3$を尖度と呼ぶ

### モーメント
平均（期待値）がXの1乗、分散が２乗、歪度が３乗、尖度が４乗・・・となっていることから、<br>
確率分布の形状を考えるためには、$E(X^r)$を考えるとよい。

これをモーメントという。また、$E((X-\mu)^r)$を、$\mu$回りの$r$次モーメントという。<br>
とはいえ、大量のサンプルの累乗計算を手で行うのは、時間がかかる。

そこで、**微分によってすべてのr次モーメントを生成できる関数**を定義する。モーメントを生成する関数なので**モーメント母関数**とよぶ。

### モーメント母関数
任意の実数$t$に関する関数$e^{tX}$に$X$の確率密度関数を乗じた関数

$M_x(t)=E(e^{tX})=\int{e^{tX}f(x)dx}$

なぜこんな関数を定義するのか？キーワードは

- マクローリン展開
- r回微分

の2つ。

マクローリン展開：
$e^x=1+\frac{x^1}{1!}+\frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+\frac{x^5}{5!}+\frac{x^6}{6!}・・・$

↑の$x→tX$に置き換えると、

$e^{tX}=1+\frac{(tX)^1}{1!}+\frac{(tX)^2}{2!}+\frac{(tX)^3}{3!}+\frac{(tX)^4}{4!}+\frac{(tX)^5}{5!}+\frac{(tX)^6}{6!}・・・$

今度は、↑を$X$の関数と見なして両辺の期待値を取る

$E(e^{tX})=1+tE(X)+\frac{t^2E(X^2)}{2!}+\frac{t^3E(X^3)}{3!}+・・・$

となり、$X$の$r$次モーメントを含む式になる。

これが**モーメントを生成する**の意味。以降は$t$に関する関数$M_x(t)$とする。

さらにこれをtについて微分する。

$\displaystyle Mx(t)'=　　E(X)+tE(X^2)+\frac{t^2E(X^3)}{2!}+\frac{t^3E(X^4)}{3!}+・・・$

$\displaystyle Mx(t)''=　　　　　　E(X^2)+tE(X^3)+\frac{t^2E(X^4)}{2!}+\frac{t^3E(X^5)}{3!}+・・・$

$t=0$のとき、先頭の項しか残らず、モーメント母関数（$t=0$）の$r$次導関数は、確率変数Xの$r$次モーメントに一致する。

したがって、母関数作る→$r$回微分する→$t=0$を代入<br>
で簡単に$E(X^r)$が計算できる。

また、確率変数$X,Y$が独立であるとき、

$$\displaystyle M_{X+Y}(t)\\
=E(e^{t(X+Y)})\\
=E(e^{tX})E(e^{tY})\\
=M_X(t)M_Y(t) $$

### チェビシェフの不等式

平均$\mu$と分散$\sigma$がわかっていて、確率分布がわからない（学力テストの結果など）とき、$X-\mu$が指定の範囲を超える確率を、チェビシェフの不等式である程度特定できる。

$P(|X-\mu|\geqq k\sigma) \leqq 1/k^2$

逆に、一定の範囲内にある確率は、$\geqq1-1/k^2$と計算する。

## 離散型確率分布と平均・分散
|名称|確率密度関数|E(X)|V(X)|
|---|---|---|---|
|超幾何分布|$_MC_x・_{N-M}C_{n-x}/_NC_n$|$np$|$np(1-p){(M-n)/(N-1)}$※|
|二項分布|$_nC_kp^k(1-p)^{n-k}$|$np$|$np(1-p)$|
|幾何分布|$p(1-p)^{x-1}$|$1/p$|$(1-p)/p^2$|
|ポアソン分布|$e^{-\lambda}\frac{\lambda^{-x}}{x!}$|$\lambda$|$\lambda$|
|一様分布|$\frac{1}{N}$|$(N+1)/2$|$(N^2-1)/12$|
※p=M/N

## 連続型確率分布と平均・分散

|名称|確率密度関数|E(X)|V(X)|備考|
|---|---|---|---|---|
|指数分布|$\lambda e^{-\lambda x}$|$1/\lambda$|$1/\lambda^2$|積分して($1-e^{-\lambda x}$)、故障率が一定の<br>設備が壊れるまでの待ち時間を計算する|
|ガンマ分布|$\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}$|$\alpha/\lambda$|$\alpha/\lambda^2$|指数分布を一般化したもの。$x^{\alpha-1}$が<br>無限大に発散するので、積分したら1になるように、ガンマ関数で割ったものを確率密度関数としている(規格化).。<br>$\Gamma(\alpha)=\int_{0}^{x}x^{\alpha-1}e^{-\lambda x}dx$|
|ベータ分布|$x^{\alpha-1}(1-x)^{\beta-1}/\Beta(\alpha,\beta)$|$\alpha/(\alpha+\beta)$|$\alpha\beta/(\alpha+\beta)^2(\alpha+\beta+1)$|ガンマ関数と同じくベータ関数で規格化している。<br>$\Beta(\alpha,\beta)=\int_0^1x^\alpha(1-x)^{1-\beta}dx$<br>$\alpha>0,\beta>0$|
|対数正規分布|$\frac{1}{2\pi\sigma x}exp(-logx-\mu)^2/2\sigma^2)$|$exp(\mu+\sigma^2/2)$|$exp(2\mu+2\sigma^2)^-exp(2\mu+\sigma^2)$|年間所得のように相対的に大きい値の分布が少ないとき、正規分布の$x-\mu$を$logx-\mu$に置き換える|
|パレート分布|$(a/x_0)(x_0/x)^{a+1}$|$ax_0/(a-1)$|$\frac{ax_0^2}{a-2}-(\frac{ax_0}{a-2})^2$|パレート分布は対数正規分布のうち、$x$の値が大きく$f(x)$が小さい部分。そのため、最小値は0より大きい定数$x_0$。$a$はパラメータ|

## 9 標本分布

### 基本的な考え方
おそらくここからして理解できていないので、<br>
どの手法で問題を解くかの判断が遅くなってる。

- 統計的推測において知りたいのは、母集団分布である
- ひとつひとつの標本$X_i$は、この母集団分布に従う確率変数であると考える
- 事前に母集団分布が正規/二項/幾何/指数/ポアソンetcであることがわかっており、該当する分布の母数（パラメータ、$\mu 　\sigma 　\lambda$など）を推定する→パラメトリック検定
- どのタイプの分布系なのかがわからない場合は、母平均・母分散・尖度・歪度、中央値、最頻値等から分布形も推定する→ノンパラメトリック検定
- 母数の推定に使われる値（標本平均、不偏分散etc）を統計量という
- 母平均は標本平均の平均
- 標本平均が母平均の分布に従い、大体の値が決まっているという前提に立つと、標本のうち（最後の）ひとつは、とりうる値の範囲が制限される（10=1+2+3+?　だった場合、？の部分は自動的に決まってしまう）ので、不偏分散は$n$ではなく$n-1$を使用する（自由度）

### 有限母集団
$n$が十分に大きくないときは、不偏分散が過大に出てしまう。
全標本数がNで、ここから$n$個づつサンプリングして平均を求めるとき、

$V(\bar X)=\frac{N-n}{N-1}・\frac{\sigma^2}{n}$

のように不偏分散を修正する（$\frac{N-n}{N-1}$を有限母集団修正という）

### P値

統計的仮説検定において、帰無仮説の元で検定統計量がその値となる確率のこと。P値が小さいほど、検定統計量がその値となることはあまり起こりえないことを意味する。

一般的にP値が5％または1％以下の場合に帰無仮説を偽として棄却し、対立仮説を採択する。

# 12 仮説検定

## 第1種の過誤

帰無仮説を誤って棄却してしまうこと（＝有意水準の棄却率）

## 第２種の過誤

帰無仮説を棄却せずに残してしまうこと

## 検出力

第２の過誤を犯さない確率＝帰無仮説が正しくないときに、ちゃんと棄却する確率